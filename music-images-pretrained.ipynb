{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81fbd868-7caf-4c23-af3e-fd7b60dc521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "101\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 8s 514ms/step - loss: 1.8791 - accuracy: 0.2636 - val_loss: 1.2164 - val_accuracy: 0.4930\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 5s 506ms/step - loss: 1.2145 - accuracy: 0.4152 - val_loss: 0.7598 - val_accuracy: 0.6901\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 5s 492ms/step - loss: 0.9630 - accuracy: 0.5576 - val_loss: 0.6146 - val_accuracy: 0.7606\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 5s 497ms/step - loss: 0.8939 - accuracy: 0.5758 - val_loss: 0.5527 - val_accuracy: 0.7606\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 6s 509ms/step - loss: 0.8047 - accuracy: 0.6545 - val_loss: 0.4978 - val_accuracy: 0.7887\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 5s 488ms/step - loss: 0.7718 - accuracy: 0.6606 - val_loss: 0.4423 - val_accuracy: 0.8169\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.7619 - accuracy: 0.6455 - val_loss: 0.3985 - val_accuracy: 0.8451\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 5s 485ms/step - loss: 0.7760 - accuracy: 0.6667 - val_loss: 0.3814 - val_accuracy: 0.8310\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 5s 492ms/step - loss: 0.7364 - accuracy: 0.6727 - val_loss: 0.3541 - val_accuracy: 0.8451\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 5s 495ms/step - loss: 0.7163 - accuracy: 0.6939 - val_loss: 0.3334 - val_accuracy: 0.8592\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 5s 478ms/step - loss: 0.7074 - accuracy: 0.6758 - val_loss: 0.3002 - val_accuracy: 0.9014\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 5s 496ms/step - loss: 0.7101 - accuracy: 0.6788 - val_loss: 0.2828 - val_accuracy: 0.9155\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 5s 475ms/step - loss: 0.7169 - accuracy: 0.6515 - val_loss: 0.2791 - val_accuracy: 0.9296\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 5s 490ms/step - loss: 0.6747 - accuracy: 0.6970 - val_loss: 0.2731 - val_accuracy: 0.9155\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 5s 494ms/step - loss: 0.6834 - accuracy: 0.6727 - val_loss: 0.2665 - val_accuracy: 0.9155\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 5s 478ms/step - loss: 0.7235 - accuracy: 0.6727 - val_loss: 0.2582 - val_accuracy: 0.9155\n",
      "3/3 - 1s - loss: 0.2582 - accuracy: 0.9155 - 814ms/epoch - 271ms/step\n",
      "Test accuracy:  0.9154929518699646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17392), started 4:28:42 ago. (Use '!kill 17392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e834dd0eabdcd114\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e834dd0eabdcd114\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS']='1'\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "import datetime\n",
    "\n",
    "# Path to dataest\n",
    "folder_path = \"C:/Users/Student/Desktop/IzzyL/Projects/MusicImages/dataset\"\n",
    "# List of classes\n",
    "subfolders = os.listdir(folder_path)\n",
    "\n",
    "# Variables\n",
    "image_arrays = [] # The numerical data of the images\n",
    "image_labels = [] # The labels for each image\n",
    "img_rows, img_cols = 224, 224 # The desired size of each image\n",
    "\n",
    "# Finds images of each instrument\n",
    "for instrument in subfolders:\n",
    "    images_names = os.path.join(folder_path, instrument)\n",
    "    images = os.listdir(images_names)\n",
    "    # Processes the images\n",
    "    for file in images:\n",
    "        image_label = instrument # Uses the folder name to append the label\n",
    "        image_labels.append(image_label)\n",
    "        image_path = os.path.join(folder_path, instrument, file) # Finds the path to each image\n",
    "        img = Image.open(image_path) # Opens the image from the path\n",
    "        padding_color = (255, 255, 255) # Sets the padding color to white\n",
    "        width, height = img.size\n",
    "        if width > 224:\n",
    "            img = img.resize((224, 224), Image.Resampling.LANCZOS)\n",
    "            if height > 224:\n",
    "                img = img.resize((224, 224), Image.Resampling.LANCZOS)\n",
    "            else:\n",
    "                img = ImageOps.pad(img, (img_rows, img_cols), color=padding_color)\n",
    "        else:\n",
    "            img = ImageOps.pad(img, (img_rows, img_cols), color=padding_color) # Pads the image so they're all the same size\n",
    "        image_array = np.array(img) # Converts images to numerical arrays\n",
    "        if image_array.shape == (224, 224, 3):\n",
    "            image_arrays.append(image_array) # Appends array to list\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "image_labels.pop(101)\n",
    "\n",
    "image_labels = np.array(image_labels) # Converts labels to numpy array\n",
    "\n",
    "print(len(image_arrays))\n",
    "print(len(image_labels))\n",
    "\n",
    "data = pd.DataFrame(zip(image_arrays, image_labels), columns=['Arrays', 'Labels']) # Creates dataframe from arrays and labels\n",
    "\n",
    "num_classes = 4 # Number of classes\n",
    "input_shape = (img_rows, img_cols, 3) # Sets the input shape for the model\n",
    "\n",
    "y = data['Labels'] # Sets the variable for the labels\n",
    "\n",
    "X = np.stack(data['Arrays'].values) # Consolidates training images\n",
    "X = X.astype('float32') / 255.0 # Converts images to float32 and makes each value between 0 and 1\n",
    "y = pd.get_dummies(y) # One-hot encodes labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42) # Splits data into train and test\n",
    "\n",
    "# Data augmentation\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range = 60,\n",
    "        shear_range = 0.4,\n",
    "        zoom_range = 0.4,\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = True,\n",
    "        brightness_range = (0.5, 1.5))\n",
    "\n",
    "n_aug = 10\n",
    "\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    for _ in range(n_aug):\n",
    "        augmented = train_datagen.random_transform(X_train[i])\n",
    "        augmented_images.append(augmented)\n",
    "        augmented_labels.append(y_train.iloc[i])\n",
    "\n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "X_combined = np.concatenate([X_train, augmented_images], axis=0)\n",
    "y_combined = np.concatenate([y_train, augmented_labels], axis=0)\n",
    "\n",
    "X_combined = tf.convert_to_tensor(X_combined, dtype=tf.float32)\n",
    "y_combined = tf.convert_to_tensor(y_combined, dtype=tf.float32)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "\n",
    "# Making the model\n",
    "\n",
    "INPUT_SHAPE = [None, img_rows, img_cols, 3]\n",
    "OUTPUT_SHAPE = 4\n",
    "MODEL_URL = \"https://kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/1\"\n",
    "\n",
    "def create_model():\n",
    "    input_layer = tf.keras.Input(shape=(224, 224, 3))\n",
    "    feature_extractor = hub.KerasLayer(\n",
    "        \"https://kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/1\",\n",
    "        trainable=False\n",
    "    )(input_layer)\n",
    "    output_layer = tf.keras.layers.Dense(4, activation=\"softmax\")(feature_extractor)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Callback\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "def create_tensorboard_callback():\n",
    "    logdir = \"C:/Users/Student/Desktop/IzzyL/Projects/MusicImages/logdir\"\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return tf.keras.callbacks.TensorBoard(logdir)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3)\n",
    "\n",
    "# Training the model\n",
    "\n",
    "def train_model():\n",
    "    model = create_model()\n",
    "    tensorboard = create_tensorboard_callback()\n",
    "    model.fit(X_combined, y_combined, epochs=100, validation_data=(X_test, y_test), validation_freq=1, callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_model()\n",
    "\n",
    "# Evaluating the model\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Test accuracy: \", scores[1])\n",
    "\n",
    "# Saving the model\n",
    "model.save(\"inst-classification.keras\")\n",
    "\n",
    "%tensorboard --logdir C:/Users/Student/Desktop/IzzyL/Projects/MusicImages/logdir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
